# -*- coding: utf-8 -*-
"""dog_breed_detection (2).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sD_in7Ym2mkVGILIFHav0COFtyIbc5bT
"""

from IPython.display import display, clear_output
from ipywidgets import Button, HBox, Label
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import comet_ml
import wandb
from ultralytics import YOLO
import torch
import cv2
import PIL.Image as Image
import os
import shutil
import pathlib
import sys
import yaml
import xmltodict
import zipfile
import json
import yaml
import torch

if __name__ == "__main__":

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"Using device: {device}")

    # Define dataset paths (Update these paths if needed)

    ROOT_DIR = pathlib.Path(r"C:\Users\Harris\PycharmProjects\DogDetector")
    ANNOTATIONS_PATH = ROOT_DIR / 'annotations'
    IMAGES_PATH = ROOT_DIR / 'images'

    # Define paths for saving processed data
    NEW_DATA_PATH = ROOT_DIR / "data"
    NEW_ANNOTATIONS_PATH = NEW_DATA_PATH / "annotations"
    SLIDES_PATH = ROOT_DIR / "slides"

    # Create necessary directories
    os.makedirs(NEW_ANNOTATIONS_PATH, exist_ok=True)
    os.makedirs(SLIDES_PATH, exist_ok=True)

    # Change working directory
    os.chdir(ROOT_DIR)


    RANDOM_SEED = 42
    np.random.seed(RANDOM_SEED)
    torch.manual_seed(RANDOM_SEED)

    """## Model & Dataset Config"""

    num_devices=1

    if torch.cuda.is_available():
        num_devices = torch.cuda.device_count()
        device = [i for i in range(num_devices)]
        device_name = torch.cuda.get_device_name()
    elif torch.backends.mps.is_available():
        device = "mps"
        device_name = "mps"
    else:
        device = "cpu"
        device_name = "cpu"


    # Dataset
    TEST_TRAIN_SPLIT = 0.15
    VALIDATION_TRAIN_SPLIT = 0.15
    # Model Vars
    IMAGE_SIZE = 640
    # Training
    PROJECT_NAME = "dog_breed_detection"
    DEVICE = device
    BATCH_SIZE = 16
    EPOCHS = 35

    print(f"Using {device_name} as the Backend.")
    print(f"Number of Devices: {num_devices}")


    with zipfile.ZipFile('Dog Breed Dataset.zip', 'r') as zip_ref:
        zip_ref.extractall('.')



    breed_dir_name = [
        breed
        for breed in sorted(os.listdir('images/Images'))
        if not breed.startswith(".") and os.path.isdir((os.path.join('images/Images', breed)))
    ]
    print(f"Number of breeds: {len(breed_dir_name)}")
    print(f"First 5 breeds: {breed_dir_name[:5]}")


    from pathlib import Path
    # Initialize dataset DataFrame
    dataset_df = pd.DataFrame(columns=["breed", "image_path", "annotation_path"])

    # Iterate through each breed directory
    for i, breed_dir in enumerate(breed_dir_name):
        breed_name = " ".join(breed_dir.replace("_", "-").split("-")[1:]).title()

        breed_images_dir_path = Path("images/Images") / breed_dir
        breed_annotations_dir_path = Path("annotations/Annotation") / breed_dir

        breed_images_name = [
            image
            for image in sorted(os.listdir(breed_images_dir_path))
            if not image.startswith(".") and image.endswith((".jpg", ".jpeg", ".png"))
        ]
        breed_annotations_name = [
            image.split(".")[0]
            for image in breed_images_name
        ]

        breed_images_path = [
            (breed_images_dir_path / image).as_posix()  # Convert Path object to string
            for image in breed_images_name
            if (breed_images_dir_path / image).is_file()  # Check if the file exists
        ]

        breed_annotations_path = [
            (breed_annotations_dir_path / annotation).as_posix()  # Convert Path object to string
            for annotation in breed_annotations_name
            if (breed_annotations_dir_path / annotation).is_file()  # Check if the file exists
        ]

        dataset_df = pd.concat([dataset_df, pd.DataFrame({
            "breed": breed_name,
            "image_path": breed_images_path,
            "annotation_path": breed_annotations_path
        })])

        if i % 10 == 0:
            print(f"Loading... {int(i / 1.20)}% done")

    # Display first few rows
    print(dataset_df.head())

    def read_txt(file_path):
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        return content

    print(read_txt(dataset_df.iloc[0]['annotation_path']))

    dataset_df_path = NEW_DATA_PATH / "dataset_df.csv"
    dataset_df = dataset_df.sort_values(by=["breed", "image_path"])
    dataset_df.to_csv(dataset_df_path, index=False)

    dataset_df = pd.read_csv(dataset_df_path)
    print(dataset_df.head())



    breeds = dataset_df["breed"].unique()
    breeds_dict = {i: breed for i, breed in enumerate(breeds)}

    breed_id_dict = {breed: i for i, breed in breeds_dict.items()}


    new_annotations = []
    for i, annotation_path in enumerate(dataset_df["annotation_path"]):
        annotation_path = pathlib.Path(annotation_path)
        new_annotation_path = NEW_ANNOTATIONS_PATH / annotation_path.parent.name
        os.makedirs(new_annotation_path, exist_ok=True)
        annotation_name = annotation_path.name

        annotation_data = xmltodict.parse(annotation_path.read_text())
        image_w, image_h = (
            int(annotation_data["annotation"]["size"]["width"]),
            int(annotation_data["annotation"]["size"]["height"])
        )
        final_data = ""
        objects = annotation_data["annotation"]["object"]
        if not isinstance(objects, list):
            objects = [objects]

        for obj in objects:
            breed = obj["name"]
            xmin, ymin, xmax, ymax = (
                int(obj["bndbox"]["xmin"]),
                int(obj["bndbox"]["ymin"]),
                int(obj["bndbox"]["xmax"]),
                int(obj["bndbox"]["ymax"])
            )
            obj_h = ymax - ymin
            obj_w = xmax - xmin
            class_id = breed_id_dict[breed.replace("_", " ").replace("-", " ").title()]
            x, y, w, h = (
                (xmin + obj_w/2) / image_w,
                (ymin + obj_h/2) / image_h,
                (obj_w) /image_w ,
                (obj_h) / image_h
            )

            final_data += f"{class_id} {x} {y} {w} {h}\n"

        if i%2000==0:
            print(f"{i} done")
        new_annotation_path = new_annotation_path / (annotation_name+".txt")
        new_annotation_path.write_text(final_data)
        new_annotations.append(new_annotation_path)

    dataset_df["new_annotation_path"] = new_annotations
    dataset_df.to_csv(dataset_df_path, index=False)

    dataset_df = dataset_df.sample(frac=1).reset_index(drop=True)


    def read_txt(file_path):
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        return content



    test_split = TEST_TRAIN_SPLIT

    test_df = dataset_df.sample(frac=test_split)
    train_df = dataset_df.drop(test_df.index)

    train_df = train_df.reset_index(drop=True)
    test_df = test_df.reset_index(drop=True)

    train_df_path = NEW_DATA_PATH / "train_df.csv"
    test_df_path = NEW_DATA_PATH / "test_df.csv"

    train_df.to_csv(train_df_path, index=False)
    test_df.to_csv(test_df_path, index=False)

    val_split = VALIDATION_TRAIN_SPLIT
    val_df = train_df.sample(frac=val_split)
    train_df = train_df.drop(val_df.index)

    a,b,c = len(train_df), len(val_df), len(test_df)

    print(f"Train set has {a} images")
    print(f"Validation set has {b} images")
    print(f"Test set has {c} images")

    train_dir = NEW_DATA_PATH / "train"
    val_dir = NEW_DATA_PATH / "val"
    test_dir = NEW_DATA_PATH / "test"


    # try:
    #     for image_path, label_path in zip(train_df["image_path"], train_df["new_annotation_path"]):
    #         image_path = pathlib.Path(image_path).resolve()
    #         label_path = pathlib.Path(label_path).resolve()
    #         images_dir_path = train_dir / "images"
    #         labels_dir_path = train_dir / "labels"
    #         os.makedirs(images_dir_path, exist_ok=True)
    #         os.makedirs(labels_dir_path, exist_ok=True)
    #
    #         try:
    #             os.link(image_path, images_dir_path / image_path.name)  # Hard link
    #         except OSError:
    #             shutil.copy(image_path, images_dir_path / image_path.name)  # Copy fallback
    #
    #         try:
    #             os.link(label_path, labels_dir_path / label_path.name)
    #         except OSError:
    #             shutil.copy(label_path, labels_dir_path / label_path.name)
    #
    #     for image_path, label_path in zip(val_df["image_path"], val_df["new_annotation_path"]):
    #         image_path = pathlib.Path(image_path).resolve()
    #         label_path = pathlib.Path(label_path).resolve()
    #         images_dir_path = val_dir / "images"
    #         labels_dir_path = val_dir / "labels"
    #         os.makedirs(images_dir_path, exist_ok=True)
    #         os.makedirs(labels_dir_path, exist_ok=True)
    #
    #         try:
    #             os.link(image_path, images_dir_path / image_path.name)
    #         except OSError:
    #             shutil.copy(image_path, images_dir_path / image_path.name)
    #
    #         try:
    #             os.link(label_path, labels_dir_path / label_path.name)
    #         except OSError:
    #             shutil.copy(label_path, labels_dir_path / label_path.name)
    #
    #     for image_path, label_path in zip(test_df["image_path"], test_df["new_annotation_path"]):
    #         image_path = pathlib.Path(image_path).resolve()
    #         label_path = pathlib.Path(label_path).resolve()
    #         images_dir_path = test_dir / "images"
    #         labels_dir_path = test_dir / "labels"
    #         os.makedirs(images_dir_path, exist_ok=True)
    #         os.makedirs(labels_dir_path, exist_ok=True)
    #
    #         try:
    #             os.link(image_path, images_dir_path / image_path.name)
    #         except OSError:
    #             shutil.copy(image_path, images_dir_path / image_path.name)
    #
    #         try:
    #             os.link(label_path, labels_dir_path / label_path.name)
    #         except OSError:
    #             shutil.copy(label_path, labels_dir_path / label_path.name)
    #
    # except FileExistsError:
    #     pass

    dataset_details = {
        "path": str(NEW_DATA_PATH),
        "train": "train",
        "val": "val",
        "test": "test",

        "names": breeds_dict
    }

    dataset_yaml_path = ROOT_DIR / "detection/dataset.yaml"
    os.makedirs(dataset_yaml_path.parent, exist_ok=True)

    with open(dataset_yaml_path, "w") as f:
        yaml.dump(dataset_details, f, default_flow_style=False)

    CLASS_NAMES = list(breeds_dict.values())
    NUM_CLASSES = len(CLASS_NAMES)


    def load_image(image_path):
        image = Image.open(image_path)
        return np.array(image)

    def render_results(
        image,
        boxes: list[float],
        classes: list[int],
        give_labels: bool = True,
    ):
        # image - single image
        # boxes - list of boxes; box = [x, y, w, h]
        # labels - list of labels; label = int

        cmap = plt.get_cmap("tab20b")
        colors = np.array([cmap(i%20)[:-1] for i in range(NUM_CLASSES)]) * 255

        image_cv = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)
        image_h, image_w, _ = image_cv.shape

        for box, cls in zip(boxes, classes):
            x, y, w, h = box
            x, y, w, h = (
                x * image_w,
                y * image_h,
                w * image_w,
                h * image_h
            )

            x1, x2 = int(x - w / 2), int(x + w / 2)
            y1, y2 = int(y - h / 2), int(y + h / 2)

            b_col = colors[int(cls)]
            image_cv = cv2.rectangle(image_cv, (x1, y1), (x2, y2), b_col, 2)
            cls_name = CLASS_NAMES[int(cls)]

            # add text
            if give_labels:
                text_size, _ = cv2.getTextSize(cls_name, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)
                text_position = (x1 + 1, y2 - 2)

                image_cv = cv2.rectangle(
                    image_cv,
                    (x1, y2),
                    (x1 + text_size[0], y2 - text_size[1] - 4),
                    b_col,
                    -1,  # filled rectangle
                )
                image_cv = cv2.putText(
                    image_cv,
                    cls_name,
                    text_position,
                    cv2.FONT_HERSHEY_SIMPLEX,
                    0.6,
                    (255, 255, 255),
                    2,
                    cv2.LINE_AA,
                    False,
                )

        image = cv2.cvtColor(image_cv, cv2.COLOR_BGR2RGB)

        return image

    slide_vars = {}

    def image_slider(images, slide_name=None, num_images=8):
        slide_name = slide_name or np.random.randint(0, 100000)
        if num_images > len(images) or num_images == -1:
            num_images = len(images)

        def save_as_slides(slide_name, images):
            save_path = SLIDES_PATH / f"slide_{slide_name}"

            os.makedirs(save_path, exist_ok=True)
            try:
                shutil.rmtree(save_path)
                os.makedirs(save_path)
                for image in images:
                    image = Image.fromarray(image)
                    image.save(save_path / f"{np.random.randint(0, 100000)}.jpg")
            except Exception as e:
                print(e)
                print("Error while saving images as slides")

        def load_slides(slide_num) -> list:
            slide_path = ROOT_DIR / f"slides/slide_{slide_num}"
            images = [str(slide_path / image) for image in os.listdir(slide_path) if image.endswith(".jpg")]
            return str(slide_path), images

        save_as_slides(slide_name, images[:num_images])
        _, images = load_slides(slide_name)

        global slide_vars
        slide_vars[slide_name] = {"image_index": 0}
        current_slide = slide_vars[slide_name]

        # Show image
        def show_image():
            clear_output(wait=True)
            display(HBox([current_slide["previous_button"], current_slide["index_label"],current_slide["next_button"],],layout={'justify_content': 'center'}))
            image_path = images[current_slide["image_index"]]
            image = plt.imread(image_path)
            plt.imshow(image)
            plt.axis('off')
            plt.show()

        def update_label():
            current_slide["index_label"].value = f"{current_slide['image_index'] + 1}/{num_images}"

        def button_click(step):
            current_slide = slide_vars[slide_name]

            idx = current_slide["image_index"] + step
            idx = idx % num_images
            current_slide["image_index"] = idx
            update_label()
            show_image()

        previous_button = Button(description='Previous', button_style='info', layout={'width': 'auto'})
        previous_button.on_click(lambda x: button_click(-1))
        current_slide["previous_button"] = previous_button

        next_button = Button(description='Next', button_style='info', layout={'width': 'auto'})
        next_button.on_click(lambda x: button_click(1))
        current_slide["next_button"] = next_button

        index_label = Label(value=f"{current_slide['image_index'] + 1}/{num_images}")
        current_slide["index_label"] = index_label

        show_image()

    data_sample = dataset_df.sample(8)

    images, all_boxes, all_classes = [], [], []

    for image_path, annotation_path in zip(data_sample["image_path"], data_sample["new_annotation_path"]):
        image = load_image(image_path)
        images.append(image)

        boxes, classes = [], []
        with open(annotation_path, "r") as f:
            data = f.readlines()

        for line in data:
            cls_, x, y, w, h = line.split()
            cls_, x, y, w, h = int(cls_), float(x), float(y), float(w), float(h)
            boxes.append([x, y, w, h])
            classes.append(cls_)

        all_boxes.append(boxes)
        all_classes.append(classes)


    slide_name = 1

    result_images = []

    for idx in range(len(images)):
        image = images[idx]
        boxes = all_boxes[idx]
        classes = all_classes[idx]

        result_images.append(render_results(image, boxes, classes))

    image_slider(result_images, slide_name=slide_name)

    result_images = None


    model_file_path = os.path.join(os.getcwd(), 'yolov12n.pt')


    # Check if CUDA is available
    if torch.cuda.is_available():
        print(f"CUDA is available! You are using GPU: {torch.cuda.get_device_name(0)}")
    else:
        print("CUDA is not available. You are using the CPU.")

    # from ultralytics.utils.callbacks.raytune import on_fit_epoch_end
    EPOCHS = 50

    model_name = "yolov12n.pt"
    version = "v2.0"
    experiment_name = f"{model_name}-{version}"
    # save_dir = f"runs/train/{projext_name}"

    model_file_path = os.path.join(os.getcwd(), "yolov12n.pt")
    model = YOLO(model_file_path)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print("Starting training...")
    model.train(
        data=dataset_yaml_path,
        epochs=EPOCHS,
        imgsz=IMAGE_SIZE,
        batch=BATCH_SIZE,
        device=device,
        project=PROJECT_NAME,

        name=experiment_name,

        exist_ok=True,
        patience = 15,
        save_period=5
        )




# model_weight = "/kaggle/working/dog_breed_detection/yolov8m-v1/weights/last.pt"
# model = model = YOLO(model_weight)
# model.train(
#     box=1,
#     cls=2.5,
#     dfl=5,
#     resume=True
# )
#
# model_weight = "/kaggle/working/dog_breed_detection/yolov8m-v1/weights/last.pt"
# model = model = YOLO(model_weight)
# model.train(
#     box=1,
#     cls=5,
#     dfl=8,
#     resume=True
# )

